{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7e85b41",
   "metadata": {},
   "source": [
    "<!--Información del curso-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figuras/banner_dl2.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d957d080",
   "metadata": {},
   "source": [
    "# ✋ MediaPipe Hands\n",
    "\n",
    "**MediaPipe Hands** es un modelo de **detección y seguimiento de manos en tiempo real**. Utiliza una combinación de redes neuronales para identificar **21 puntos clave** en cada mano y proporciona una representación estructural útil para diversas aplicaciones.  \n",
    "\n",
    "\n",
    "## ¿Cómo funciona MediaPipe Hands?  \n",
    "El modelo opera en dos fases principales:  \n",
    "\n",
    "**Detección de la mano** → Encuentra la posición de la mano en la imagen.  \n",
    "**Estimación de los puntos clave** → Predice la ubicación de los **21 landmarks** en la mano detectada.  \n",
    "\n",
    "MediaPipe Hands puede detectar **una o ambas manos** y permite realizar gestos, seguimiento de movimientos y control por gestos en aplicaciones interactivas.  \n",
    "\n",
    "\n",
    "\n",
    "##  Puntos clave de la mano en MediaPipe Hands  \n",
    "Cada mano detectada tiene **21 puntos clave** numerados de la siguiente manera:  \n",
    "\n",
    "**Puntos principales**  \n",
    "- **0** → Muñeca  \n",
    "- **1-4** → Pulgar  \n",
    "- **5-8** → Índice  \n",
    "- **9-12** → Medio  \n",
    "- **13-16** → Anular  \n",
    "- **17-20** → Meñique \n",
    "\n",
    "\n",
    "\n",
    "## Opciones de configuración \n",
    "\n",
    "#### STATIC_IMAGE_MODE (POR DEFECTO FALSE) \n",
    "Puede tener valores de True o False. Cuando se le asigna False, entonces trata a las imágeness de entrada como un videostream, de tal manera que aplica el modelo de detección de palma y el modelo hand landmarks en un principio, pero luego realiza tracking para obtener la nueva ubicación de la mano, basándose en los puntos de referencia. De este modo, solo se invocará nuevamente al detector de palmas cuando no se hayan identificado los 21 puntos. \n",
    "\n",
    "Cuando se le asigna True, entonces los detectores estarán aplicádose en cada imagen, por lo que es mejor usarla en caso de que se trate de imágenes que no tengan que ver entre sí. \n",
    "\n",
    "####  MAX_NUM_HANDS (POR DEFECTO 2) \n",
    "Número máximo de manos por detectar. \n",
    "\n",
    "####  MIN_DETECTION_CONFIDENCE (POR DEFECTO 0.5) \n",
    "Valor mínimo de confianza del modelo de detección de manos, para que la detección sea considerada como exitosa. Sus valores comprenden de 0 a 1. \n",
    "\n",
    "####  MIN_TRACKING_CONFIDENCE (POR DEFECTO 0.5) \n",
    "Valor mínimo de confianza del modelo de rastreo de los landmark, para que el rastreo de los 21 puntos sea considerado como exitoso. En caso de no serlo, se invocará al detector de manos en la siguiente imagen. \n",
    "Este es ignorado si static_image_mode está en True. \n",
    "\n",
    "\n",
    "* https://developers.google.com/mediapipe/solutions/vision/hand_landmarker\n",
    "* https://mediapipe.readthedocs.io/en/latest/solutions/hands.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb32c05",
   "metadata": {},
   "source": [
    "<!--Información del curso-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figuras/hand-landmarks.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "21d6f514",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerías básicas de esta notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a249e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "ffcbd510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a367f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44a739b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d170dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f00fe4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
